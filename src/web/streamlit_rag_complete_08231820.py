#!/usr/bin/env python3
"""
RAG ì„±ëŠ¥ ê°œì„  ë¹„êµ Streamlit ì¸í„°í˜ì´ìŠ¤ v08231820
ì™„ë²½í•œ RAG ì„±ëŠ¥ ë¹„êµ ì‹œìŠ¤í…œì˜ ì›¹ ì¸í„°í˜ì´ìŠ¤
ì‹¤ì‹œê°„ ë¶„ì„, ì§„í–‰ë¥  í‘œì‹œ, ìƒì„¸ ì°¨íŠ¸, LangSmith ì¶”ì  í†µí•©
"""

import os
import json
import time
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
from datetime import datetime
from pathlib import Path
import streamlit as st
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
import sys
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from src.rag_improvement_complete_08231820 import RAGImprovementComparator, save_results_multiple_formats
from src.utils.version_manager import VersionManager
from src.utils.langsmith_simple import LangSmithSimple
from src.utils.path_utils import ensure_directory_exists

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ§  RAG ì„±ëŠ¥ ê°œì„  ì™„ë²½ ë¶„ì„ v08231820",
    page_icon="ğŸ§ ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§ (ì—…ê·¸ë ˆì´ë“œ)
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea, #764ba2);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .analysis-box {
        background: linear-gradient(135deg, #f093fb, #f5576c);
        padding: 1.5rem;
        border-radius: 8px;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    .improvement-score {
        font-size: 2rem;
        font-weight: bold;
        text-align: center;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem;
    }
    .score-excellent { background: linear-gradient(135deg, #4facfe, #00f2fe); color: white; }
    .score-good { background: linear-gradient(135deg, #43e97b, #38f9d7); color: white; }
    .score-fair { background: linear-gradient(135deg, #fa709a, #fee140); color: white; }
    .score-poor { background: linear-gradient(135deg, #ff9a9e, #fecfef); color: #333; }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
        border: 2px solid #f0f0f0;
    }
    .metric-card:hover {
        border-color: #667eea;
        transform: translateY(-2px);
        transition: all 0.3s ease;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def initialize_system():
    """ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ìºì‹±)"""
    load_dotenv()
    
    # ë²„ì „ ê´€ë¦¬ì ì´ˆê¸°í™”
    version_manager = VersionManager()
    
    # LangSmith ì„¤ì •
    from omegaconf import OmegaConf
    cfg = OmegaConf.create({
        'langsmith': {
            'enabled': True,
            'project_name': 'streamlit-rag-complete-v08231820',
            'session_name': f'streamlit-session_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
        }
    })
    
    langsmith_manager = LangSmithSimple(cfg, version_manager)
    
    # ë¹„êµê¸° ì´ˆê¸°í™”
    comparator = RAGImprovementComparator(version_manager, langsmith_manager)
    
    return comparator, version_manager

def get_score_class(score):
    """ì ìˆ˜ì— ë”°ë¥¸ CSS í´ë˜ìŠ¤ ë°˜í™˜"""
    if score >= 80:
        return "score-excellent"
    elif score >= 60:
        return "score-good"
    elif score >= 40:
        return "score-fair"
    else:
        return "score-poor"

def create_improvement_chart(results):
    """ê°œì„  ì ìˆ˜ ë¹„êµ ì°¨íŠ¸ ìƒì„±"""
    data = []
    
    for q_id, q_data in results.get('questions', {}).items():
        for model in ['GPT-4o', 'Claude-3.5']:
            if model in q_data.get('improvements', {}):
                improvement = q_data['improvements'][model]
                data.append({
                    'Question': f"Q{q_id[-1]}",
                    'Model': model,
                    'Score': improvement['overall_score'],
                    'Question_Full': q_data['question'][:50] + '...'
                })
    
    if not data:
        return None
    
    df = pd.DataFrame(data)
    
    fig = px.bar(
        df, 
        x='Question', 
        y='Score', 
        color='Model',
        title='RAG ê°œì„  ì ìˆ˜ ë¹„êµ (ì§ˆë¬¸ë³„)',
        hover_data=['Question_Full'],
        color_discrete_map={
            'GPT-4o': '#3498db',
            'Claude-3.5': '#e74c3c'
        }
    )
    
    fig.update_layout(
        yaxis_title="ê°œì„  ì ìˆ˜ (0-100)",
        xaxis_title="ì§ˆë¬¸",
        height=400,
        hovermode='x unified'
    )
    
    return fig

def create_response_time_chart(results):
    """ì‘ë‹µ ì‹œê°„ ë³€í™” ì°¨íŠ¸ ìƒì„±"""
    data = []
    
    for q_id, q_data in results.get('questions', {}).items():
        for model in ['GPT-4o', 'Claude-3.5']:
            if model in q_data.get('responses', {}):
                responses = q_data['responses'][model]
                pure_time = responses.get('pure', {}).get('response_time', 0)
                rag_time = responses.get('rag', {}).get('response_time', 0)
                
                data.extend([
                    {
                        'Question': f"Q{q_id[-1]}",
                        'Model': model,
                        'Type': 'Pure LLM',
                        'Response_Time': pure_time
                    },
                    {
                        'Question': f"Q{q_id[-1]}",
                        'Model': model,
                        'Type': 'RAG Applied',
                        'Response_Time': rag_time
                    }
                ])
    
    if not data:
        return None
    
    df = pd.DataFrame(data)
    
    fig = px.bar(
        df, 
        x='Question', 
        y='Response_Time', 
        color='Type',
        facet_col='Model',
        title='ì‘ë‹µ ì‹œê°„ ë¹„êµ (ìˆœìˆ˜ LLM vs RAG)',
        color_discrete_map={
            'Pure LLM': '#95a5a6',
            'RAG Applied': '#2ecc71'
        }
    )
    
    fig.update_layout(height=400)
    fig.update_yaxes(title="ì‘ë‹µ ì‹œê°„ (ì´ˆ)")
    
    return fig

def create_metrics_radar_chart(results):
    """ëª¨ë¸ë³„ ì¢…í•© ì„±ëŠ¥ ë ˆì´ë” ì°¨íŠ¸"""
    summary = results.get('summary', {})
    model_averages = summary.get('model_averages', {})
    
    if len(model_averages) < 2:
        return None
    
    models = list(model_averages.keys())
    
    # ë©”íŠ¸ë¦­ ì •ê·œí™” (0-100 ìŠ¤ì¼€ì¼)
    metrics = ['ê°œì„ ì ìˆ˜', 'íš¨ìœ¨ì„±', 'ì •í™•ì„±', 'ì†ë„', 'í™œìš©ë„']
    
    model_data = {}
    for model in models:
        avg_data = model_averages[model]
        model_data[model] = [
            avg_data.get('avg_improvement_score', 0),  # ê°œì„ ì ìˆ˜
            max(0, 100 - abs(avg_data.get('avg_time_increase', 0)) * 10),  # íš¨ìœ¨ì„± (ì‹œê°„ì¦ê°€ íŒ¨ë„í‹°)
            min(100, avg_data.get('avg_improvement_score', 0) * 1.2),  # ì •í™•ì„±
            max(0, 100 - avg_data.get('avg_time_increase', 0) * 20),  # ì†ë„
            min(100, avg_data.get('avg_cases_used', 0) * 25)  # í™œìš©ë„ (íŒë¡€ì‚¬ìš©)
        ]
    
    fig = go.Figure()
    
    colors = ['#3498db', '#e74c3c']
    for i, (model, values) in enumerate(model_data.items()):
        fig.add_trace(go.Scatterpolar(
            r=values + [values[0]],  # ë‹«íŒ ë‹¤ê°í˜•ì„ ìœ„í•´
            theta=metrics + [metrics[0]],
            fill='toself',
            name=model,
            line_color=colors[i % len(colors)]
        ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100]
            )),
        title="ëª¨ë¸ë³„ ì¢…í•© ì„±ëŠ¥ ë¹„êµ",
        height=500
    )
    
    return fig

def run_analysis_with_progress(comparator, questions, temperature):
    """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ë¶„ì„ ì‹¤í–‰"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    current_step = 0
    total_steps = len(questions) * 2 * 2  # questions * models * (pure+rag)
    
    def progress_callback(progress):
        nonlocal current_step
        current_step = int(progress * total_steps)
        progress_bar.progress(progress)
        
        if progress < 1.0:
            status_text.text(f"ë¶„ì„ ì§„í–‰ ì¤‘... ({current_step}/{total_steps})")
        else:
            status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
    
    # ë¶„ì„ ì‹¤í–‰
    results = comparator.compare_models(questions, temperature, progress_callback)
    
    time.sleep(1)  # ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ ì‹œê°„
    progress_bar.empty()
    status_text.empty()
    
    return results

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ§  RAG ì„±ëŠ¥ ê°œì„  ì™„ë²½ ë¶„ì„ ì‹œìŠ¤í…œ</h1>
        <h3>v08231820 â€¢ LangSmith ì¶”ì  â€¢ ì‹¤ì‹œê°„ ì‹œê°í™”</h3>
        <p>ìˆœìˆ˜ LLM vs RAG ì ìš© ì„±ëŠ¥ ë¹„êµ â€¢ GPT-4o â€¢ Claude-3.5 â€¢ 17ê°œ ëŒ€ë²•ì› íŒë¡€</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        
        # ì§ˆë¬¸ ì„ íƒ
        available_questions = [
            "ì·¨ì—…ê·œì¹™ì„ ê·¼ë¡œìì—ê²Œ ë¶ˆë¦¬í•˜ê²Œ ë³€ê²½í•  ë•Œ ì‚¬ìš©ìê°€ ì§€ì¼œì•¼ í•  ë²•ì  ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "í‡´ì§ê¸ˆ ì§€ê¸‰ ê¸°ì¼ì„ ì—°ì¥í•˜ëŠ” í•©ì˜ë¥¼ í–ˆë”ë¼ë„ ì—°ì¥ëœ ê¸°ì¼ê¹Œì§€ ì§€ê¸‰í•˜ì§€ ì•Šìœ¼ë©´ í˜•ì‚¬ì²˜ë²Œì„ ë°›ë‚˜ìš”?",
            "ë¶€ë‹¹í•´ê³  êµ¬ì œì‹ ì²­ì˜ ìš”ê±´ê³¼ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ê·¼ë¡œìì˜ ì—…ë¬´ìƒ ì¬í•´ ì¸ì • ê¸°ì¤€ê³¼ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì‚¬ì—…ì£¼ê°€ ê·¼ë¡œê³„ì•½ì„ í•´ì§€í•  ë•Œ ì§€ì¼œì•¼ í•  ë²•ì  ì ˆì°¨ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        ]
        
        selected_questions = st.multiselect(
            "ë¶„ì„í•  ì§ˆë¬¸ ì„ íƒ",
            available_questions,
            default=available_questions[:3],
            help="ìµœëŒ€ 5ê°œ ì§ˆë¬¸ê¹Œì§€ ì„ íƒ ê°€ëŠ¥"
        )
        
        # ì˜¨ë„ ì„¤ì •
        temperature = st.slider(
            "Temperature (ì°½ì˜ì„± ì¡°ì ˆ)",
            min_value=0.0,
            max_value=1.0,
            value=0.1,
            step=0.05,
            help="ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ë‹µë³€, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì  ë‹µë³€"
        )
        
        # ê³ ê¸‰ ì„¤ì •
        with st.expander("ğŸ”§ ê³ ê¸‰ ì„¤ì •"):
            show_raw_responses = st.checkbox("ì›ë³¸ ì‘ë‹µ í‘œì‹œ", value=False)
            auto_save = st.checkbox("ê²°ê³¼ ìë™ ì €ì¥", value=True)
            real_time_charts = st.checkbox("ì‹¤ì‹œê°„ ì°¨íŠ¸ ì—…ë°ì´íŠ¸", value=True)
        
        st.markdown("---")
        st.markdown("""
        **ğŸ“Š ë¶„ì„ ì •ë³´**
        - 17ê°œ ëŒ€ë²•ì› íŒë¡€ ë°ì´í„°
        - LangSmith ì „ì²´ ì¶”ì 
        - JSON/CSV/Markdown ë‹¤ì¤‘ ì¶œë ¥
        - ì‹¤ì‹œê°„ ì„±ëŠ¥ ì‹œê°í™”
        """)
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    comparator, version_manager = initialize_system()
    
    st.success("âœ… RAG ì„±ëŠ¥ ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“‹ ì„ íƒëœ ì§ˆë¬¸ë“¤")
        if selected_questions:
            for i, question in enumerate(selected_questions, 1):
                st.write(f"**Q{i}**: {question}")
        else:
            st.warning("ë¶„ì„í•  ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    with col2:
        st.subheader("âš¡ ë¹ ë¥¸ ì‹¤í–‰")
        
        analyze_button = st.button(
            "ğŸš€ RAG ì„±ëŠ¥ ë¶„ì„ ì‹œì‘",
            type="primary",
            use_container_width=True,
            disabled=not selected_questions
        )
        
        if st.button("ğŸ“Š ìƒ˜í”Œ ê²°ê³¼ ë³´ê¸°", use_container_width=True):
            st.info("ìƒ˜í”Œ ë¶„ì„ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤...")
    
    # ë¶„ì„ ì‹¤í–‰
    if analyze_button and selected_questions:
        st.markdown("""
        <div class="analysis-box">
            <h3>ğŸ” RAG ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰ ì¤‘</h3>
            <p>ìˆœìˆ˜ LLMê³¼ RAG ì ìš© ëª¨ë¸ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤...</p>
        </div>
        """, unsafe_allow_html=True)
        
        try:
            # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
            results = run_analysis_with_progress(comparator, selected_questions, temperature)
            
            # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
            st.session_state['analysis_results'] = results
            st.session_state['analysis_timestamp'] = datetime.now()
            
            st.success("ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
            
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.stop()
    
    # ê²°ê³¼ í‘œì‹œ
    if 'analysis_results' in st.session_state:
        results = st.session_state['analysis_results']
        
        st.markdown("---")
        st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        
        # ìš”ì•½ ë©”íŠ¸ë¦­
        summary = results.get('summary', {})
        model_averages = summary.get('model_averages', {})
        
        if model_averages:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                gpt_score = model_averages.get('GPT-4o', {}).get('avg_improvement_score', 0)
                score_class = get_score_class(gpt_score)
                st.markdown(f"""
                <div class="improvement-score {score_class}">
                    GPT-4o<br>{gpt_score:.1f}/100
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                claude_score = model_averages.get('Claude-3.5', {}).get('avg_improvement_score', 0)
                score_class = get_score_class(claude_score)
                st.markdown(f"""
                <div class="improvement-score {score_class}">
                    Claude-3.5<br>{claude_score:.1f}/100
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                total_questions = len(results.get('questions', {}))
                st.metric("ë¶„ì„ ì§ˆë¬¸ ìˆ˜", total_questions)
            
            with col4:
                total_cases = results.get('metadata', {}).get('total_cases', 0)
                st.metric("ì°¸ì¡° íŒë¡€ ìˆ˜", f"{total_cases}ê±´")
        
        # ìƒì„¸ ì°¨íŠ¸
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ ê°œì„  ì ìˆ˜", "â±ï¸ ì‘ë‹µ ì‹œê°„", "ğŸ¯ ì¢…í•© ì„±ëŠ¥", "ğŸ“‹ ìƒì„¸ ê²°ê³¼"])
        
        with tab1:
            st.subheader("RAG ê°œì„  ì ìˆ˜ ë¹„êµ")
            improvement_chart = create_improvement_chart(results)
            if improvement_chart:
                st.plotly_chart(improvement_chart, use_container_width=True)
            else:
                st.warning("ì°¨íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        with tab2:
            st.subheader("ì‘ë‹µ ì‹œê°„ ë³€í™” ë¶„ì„")
            time_chart = create_response_time_chart(results)
            if time_chart:
                st.plotly_chart(time_chart, use_container_width=True)
            else:
                st.warning("ì°¨íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        with tab3:
            st.subheader("ëª¨ë¸ë³„ ì¢…í•© ì„±ëŠ¥")
            radar_chart = create_metrics_radar_chart(results)
            if radar_chart:
                st.plotly_chart(radar_chart, use_container_width=True)
            
            # ì„±ëŠ¥ ë¹„êµ ìš”ì•½
            perf_comp = summary.get('performance_comparison', {})
            if perf_comp:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ë” ë‚˜ì€ ê°œì„ ", perf_comp.get('better_improvement', 'N/A'))
                
                with col2:
                    st.metric("ë” ë¹ ë¥¸ ì²˜ë¦¬", perf_comp.get('faster_processing', 'N/A'))
                
                with col3:
                    st.metric("ì ìˆ˜ ì°¨ì´", f"{perf_comp.get('score_difference', 0):.1f}ì ")
        
        with tab4:
            st.subheader("ì§ˆë¬¸ë³„ ìƒì„¸ ê²°ê³¼")
            
            for q_id, q_data in results.get('questions', {}).items():
                with st.expander(f"Q{q_id[-1]}. {q_data['question'][:80]}...", expanded=False):
                    
                    col1, col2 = st.columns(2)
                    
                    for i, model in enumerate(['GPT-4o', 'Claude-3.5']):
                        col = col1 if i == 0 else col2
                        
                        if model in q_data.get('improvements', {}):
                            improvement = q_data['improvements'][model]
                            responses = q_data['responses'][model]
                            
                            with col:
                                st.markdown(f"#### {model}")
                                st.metric("ê°œì„  ì ìˆ˜", f"{improvement['overall_score']:.1f}/100")
                                st.write(f"**ë¶„ì„**: {improvement['analysis']}")
                                st.write(f"**ì‹œê°„ ë³€í™”**: {improvement['response_time_change']:+.2f}ì´ˆ")
                                st.write(f"**ì‚¬ìš© íŒë¡€**: {responses['rag'].get('case_count', 0)}ê±´")
                                
                                if show_raw_responses:
                                    with st.expander(f"{model} ì›ë³¸ ì‘ë‹µ"):
                                        st.write("**ìˆœìˆ˜ LLM:**")
                                        st.code(responses['pure']['answer'][:300] + "...")
                                        st.write("**RAG ì ìš©:**")
                                        st.code(responses['rag']['answer'][:300] + "...")
        
        # ìë™ ì €ì¥
        if auto_save:
            output_dir = ensure_directory_exists("results/rag_improvement_complete")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            try:
                json_path, csv_path, report_path = save_results_multiple_formats(
                    results, Path(output_dir), timestamp
                )
                
                st.success(f"âœ… ê²°ê³¼ê°€ ìë™ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.download_button(
                        "ğŸ“„ JSON ë‹¤ìš´ë¡œë“œ",
                        data=json.dumps(results, ensure_ascii=False, indent=2),
                        file_name=f"rag_results_{timestamp}.json",
                        mime="application/json"
                    )
                
                with col2:
                    if csv_path.exists():
                        with open(csv_path, 'r', encoding='utf-8') as f:
                            st.download_button(
                                "ğŸ“Š CSV ë‹¤ìš´ë¡œë“œ",
                                data=f.read(),
                                file_name=f"rag_summary_{timestamp}.csv",
                                mime="text/csv"
                            )
                
                with col3:
                    if report_path.exists():
                        with open(report_path, 'r', encoding='utf-8') as f:
                            st.download_button(
                                "ğŸ“‹ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                                data=f.read(),
                                file_name=f"rag_report_{timestamp}.md",
                                mime="text/markdown"
                            )
                
            except Exception as e:
                st.warning(f"ìë™ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666;">
        <p><strong>ğŸ§  RAG ì„±ëŠ¥ ê°œì„  ì™„ë²½ ë¶„ì„ ì‹œìŠ¤í…œ v08231820</strong></p>
        <p>ğŸ”¬ Powered by LangChain â€¢ OpenAI â€¢ Anthropic â€¢ LangSmith â€¢ Streamlit</p>
        <p>âš–ï¸ 17ê°œ ëŒ€ë²•ì› íŒë¡€ ê¸°ë°˜ RAG ì„±ëŠ¥ ê²€ì¦ ì‹œìŠ¤í…œ</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()